{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a4968ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1909, 1006)\n"
     ]
    }
   ],
   "source": [
    "# 聚类降噪并提取特征\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema, find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "data = np.load(\"data/test_without_resp.npy\")\n",
    "peaks = np.load(\"data/test_without_resp_peaks.npy\")\n",
    "print(data.shape)\n",
    "\n",
    "# for j in range(data.reshape[0]):\n",
    "\n",
    "features_all = np.zeros(18)\n",
    "\n",
    "for j in range(data.shape[0]):\n",
    "    signal = data[j,:1000]\n",
    "    peaks2 = peaks[j,:]\n",
    "\n",
    "    peaks2 = peaks2.astype(int)\n",
    "\n",
    "#     print(peaks2)\n",
    "    for i in range(len(peaks2)-1, 0, -1):\n",
    "        if peaks2[i] == 0:\n",
    "            peaks2 = np.delete(peaks2, i)\n",
    "        else:\n",
    "            break\n",
    "#     print(peaks2)\n",
    "\n",
    "    avg_index = (peaks2[::2] + peaks2[1::2]) // 2\n",
    "    # print(avg_index)\n",
    "    # plt.plot(signal)\n",
    "    # plt.plot(peaks2,signal[peaks2],'o')\n",
    "    # plt.show()\n",
    "\n",
    "    # 使用这些平均数作为x的下标，将x切割成多个部分\n",
    "    splits = np.split(signal, avg_index)\n",
    "\n",
    "    max_length = max(len(split) for split in splits)\n",
    "\n",
    "    # 补充每个部分使其长度相等\n",
    "    padded_splits = [np.pad(split, (0, max_length - len(split))) for split in splits]\n",
    "\n",
    "    # 将这些部分堆叠成一个二维数组\n",
    "    stacked_array = np.vstack(padded_splits)\n",
    "\n",
    "    stacked_array = np.delete(stacked_array, 0, axis=0)\n",
    "\n",
    "\n",
    "    # 打印结果\n",
    "#     for i in range(stacked_array.shape[0]):\n",
    "#         plt.plot(stacked_array[i, :])\n",
    "#         plt.show()\n",
    "\n",
    "    # plt.plot(signal3)\n",
    "    # plt.plot(peaks2,signal3[peaks2],'o')\n",
    "    # plt.show()\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    class PulseClustering:\n",
    "        def __init__(self, threshold):\n",
    "            self.threshold = threshold\n",
    "            self.clusters = []\n",
    "\n",
    "        def fit(self, pulses):\n",
    "            for pulse in pulses:\n",
    "                if not self.clusters:  # 如果聚类为空，创建第一个聚类\n",
    "                    self.clusters.append([pulse])\n",
    "                else:\n",
    "                    for cluster in self.clusters:\n",
    "                        center_pulse = np.mean(cluster, axis=0)  # 计算聚类中心\n",
    "                        rmse = np.sqrt(mean_squared_error(center_pulse, pulse))  # 计算RMSE\n",
    "                        if rmse < self.threshold:  # 如果RMSE低于阈值，将脉冲添加到聚类中\n",
    "                            cluster.append(pulse)\n",
    "                            break\n",
    "                    else:  # 如果脉冲与现有的所有聚类的中心的RMSE都高于阈值，创建新的聚类\n",
    "                        self.clusters.append([pulse])\n",
    "\n",
    "        def get_clusters(self):\n",
    "            return self.clusters\n",
    "\n",
    "\n",
    "    threshold = 0.000005  # 这应该是一个你选择的阈值\n",
    "\n",
    "    clustering = PulseClustering(threshold)\n",
    "    clustering.fit(stacked_array)\n",
    "\n",
    "    clusters = clustering.get_clusters()\n",
    "\n",
    "\n",
    "    num_pulses_per_cluster = [len(cluster) for cluster in clusters]\n",
    "\n",
    "    # 打印结果\n",
    "#     for i, num_pulses in enumerate(num_pulses_per_cluster):\n",
    "#         print(f\"Cluster {i+1} contains {num_pulses} pulses.\")\n",
    "\n",
    "    max_cluster = max(clusters, key=len)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 计算最大聚类的平均脉冲\n",
    "    average_pulse = np.mean(max_cluster, axis=0)\n",
    "\n",
    "#     plt.plot(average_pulse)\n",
    "    \n",
    "    p1 = peaks2[1] - avg_index[0]\n",
    "    for wz in range(10):\n",
    "        if average_pulse[p1] < average_pulse[p1+1]:\n",
    "            p1 = p1 + 1\n",
    "        elif average_pulse[p1] < average_pulse[p1-1]:\n",
    "            p1 = p1 - 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    p2 = peaks2[2] - avg_index[0]\n",
    "    for wy in range(10):\n",
    "        if average_pulse[p2] < average_pulse[p2+1]:\n",
    "            p2 = p2 + 1\n",
    "        elif average_pulse[p2] < average_pulse[p2-1]:\n",
    "            p2 = p2 - 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "#     plt.plot(p1, average_pulse[p1],'o')\n",
    "#     plt.plot(p2, average_pulse[p2],'o')\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    # 特征提取\n",
    "\n",
    "    # 平均值\n",
    "    # P1\n",
    "    # P2\n",
    "    # P1-P2\n",
    "    # P1/P2\n",
    "    # D12\n",
    "    # D21\n",
    "    # D11\n",
    "    # D12/D21\n",
    "    # Skew1\n",
    "    # Skew2\n",
    "    # Kurt1\n",
    "    # Kurt2\n",
    "    # 方差\n",
    "    # PeakToPeak\n",
    "    # Zero Crossing Rate\n",
    "    # Energy \n",
    "    # 10s内有多少个周期\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.signal\n",
    "    import scipy.stats\n",
    "\n",
    "    # 假设 signal 是你的信号\n",
    "    signal = average_pulse  # 示例信号，你可以用你的信号替换\n",
    "\n",
    "    # 平均值\n",
    "    mean_val = np.mean(signal)\n",
    "\n",
    "    #  P1 P2\n",
    "    P1 = signal[p1]\n",
    "    P2 = signal[p2]\n",
    "    \n",
    "    # P1-P2\n",
    "    # P1/P2\n",
    "    # D12\n",
    "    D12 = peaks2[1]-peaks2[0]\n",
    "    \n",
    "    # D21\n",
    "    D21 = peaks2[2]-peaks2[1]\n",
    "    \n",
    "    # D11\n",
    "    # D12/D21\n",
    "    \n",
    "    #Sk Ku\n",
    "    Skew1 = skew(signal[:(p1+p2)//2])\n",
    "    Skew2 = skew(signal[(p1+p2)//2:])\n",
    "    Kurt1 = kurtosis(signal[:(p1+p2)//2])\n",
    "    Kurt2 = kurtosis(signal[(p1+p2)//2:])\n",
    "    \n",
    "    # 方差\n",
    "    variance = np.var(signal)\n",
    "\n",
    "    # Peak to Peak值\n",
    "    peak_to_peak = np.ptp(signal)\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    zcr = ((signal[:-1] * signal[1:]) < 0).sum()\n",
    "\n",
    "    # Energy\n",
    "    energy = np.sum(signal**2)\n",
    "    \n",
    "    # 10s内有多少个周期\n",
    "    CPS = len(peaks2)/2/10\n",
    "    \n",
    "    features = np.array([mean_val,P1,P2,P1-P2,P1/P2,D12,D21,D12+D21,D12/D21,Skew1,Skew2,Kurt1,Kurt2,variance,peak_to_peak,zcr,energy,CPS])\n",
    "    features_all = np.vstack([features_all, features])\n",
    "\n",
    "\n",
    "#     print(\"Mean Value:\", mean_val)\n",
    "#     print(\"Variance:\", variance)\n",
    "#     print(\"Peak to Peak:\", peak_to_peak)\n",
    "#     print(\"Zero Crossing Rate:\", zcr)\n",
    "#     print(\"Energy:\", energy)\n",
    "#     print(Skew1,Skew2,Kurt1,Kurt2,CPS,P1, P2)\n",
    "\n",
    "# feature = np.load(\"data/features_train_without_resp.npy\")\n",
    "# data = np.load(\"data/train_without_resp.npy\")\n",
    "# plt.plot(data[2,:1000])\n",
    "# plt.show()\n",
    "# print(feature[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48e9ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1910, 18)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(1909, 18)\n"
     ]
    }
   ],
   "source": [
    "print(features_all.shape)\n",
    "print(features_all[0,:])\n",
    "features_all = features_all[1:,:]\n",
    "print(features_all.shape)\n",
    "np.save(\"data/features_test_without_resp.npy\",features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c1c959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3879, 18)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "feature_train = np.load(\"data/features_train_without_resp.npy\")\n",
    "feature_test = np.load(\"data/features_test_without_resp.npy\")\n",
    "\n",
    "\n",
    "print(feature_train.shape)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "feature_train_without_resp_norm = scaler.fit_transform(feature_train)\n",
    "feature_test_without_resp_norm = scaler.transform(feature_test)\n",
    "np.save(\"data/features_train_without_resp_norm.npy\", feature_train_without_resp_norm)\n",
    "np.save(\"data/features_test_without_resp_norm.npy\", feature_test_without_resp_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd4c74da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.16494339605260905\n",
      "Feature 1: 0.0007699362256058653\n",
      "Feature 2: 0.00028795964146322017\n",
      "Feature 3: 0.0007169822405016651\n",
      "Feature 4: -0.030926736457222243\n",
      "Feature 5: 0.17126118587636302\n",
      "Feature 6: -0.343479875619611\n",
      "Feature 7: -0.029637391704047656\n",
      "Feature 8: 0.9734766369769158\n",
      "Feature 9: -0.30014591147256753\n",
      "Feature 10: -0.3533278943009381\n",
      "Feature 11: -0.37193977102227693\n",
      "Feature 12: -0.3297073449292556\n",
      "Feature 13: 0.14278054674492816\n",
      "Feature 14: 0.03344318779722784\n",
      "Feature 15: 0.01380197736669158\n",
      "Feature 16: 0.07598738711728514\n",
      "Feature 17: 0.029794424476385188\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "features = np.load(\"./data/features_test_without_resp_norm.npy\")\n",
    "data = np.load(\"./data/test_without_resp.npy\")\n",
    "target = data[:,1004]\n",
    "\n",
    "# target = target.ravel()\n",
    "\n",
    "# 计算每个特征和目标值之间的皮尔逊相关系数\n",
    "correlations = [pearsonr(features[:, i], target) for i in range(features.shape[1])]\n",
    "\n",
    "# 打印相关系数\n",
    "for i, correlation in enumerate(correlations):\n",
    "    print(f'Feature {i}: {correlation[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
