{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4968ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3879, 1006)\n"
     ]
    }
   ],
   "source": [
    "# 聚类降噪并提取特征\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema, find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "data = np.load(\"data/train_without_resp.npy\")\n",
    "peaks = np.load(\"data/train_without_resp_peaks.npy\")\n",
    "print(data.shape)\n",
    "\n",
    "# for j in range(data.reshape[0]):\n",
    "\n",
    "features_all = np.zeros(12)\n",
    "\n",
    "for j in range(data.shape[0]):\n",
    "    signal = data[j,:1000]\n",
    "    peaks2 = peaks[j,:]\n",
    "\n",
    "    peaks2 = peaks2.astype(int)\n",
    "\n",
    "#     print(peaks2)\n",
    "    for i in range(len(peaks2)-1, 0, -1):\n",
    "        if peaks2[i] == 0:\n",
    "            peaks2 = np.delete(peaks2, i)\n",
    "        else:\n",
    "            break\n",
    "#     print(peaks2)\n",
    "\n",
    "    avg_index = (peaks2[::2] + peaks2[1::2]) // 2\n",
    "    # print(avg_index)\n",
    "    # plt.plot(signal)\n",
    "    # plt.plot(peaks2,signal[peaks2],'o')\n",
    "    # plt.show()\n",
    "\n",
    "    # 使用这些平均数作为x的下标，将x切割成多个部分\n",
    "    splits = np.split(signal, avg_index)\n",
    "\n",
    "    max_length = max(len(split) for split in splits)\n",
    "\n",
    "    # 补充每个部分使其长度相等\n",
    "    padded_splits = [np.pad(split, (0, max_length - len(split))) for split in splits]\n",
    "\n",
    "    # 将这些部分堆叠成一个二维数组\n",
    "    stacked_array = np.vstack(padded_splits)\n",
    "\n",
    "    stacked_array = np.delete(stacked_array, 0, axis=0)\n",
    "\n",
    "\n",
    "    # 打印结果\n",
    "#     for i in range(stacked_array.shape[0]):\n",
    "#         plt.plot(stacked_array[i, :])\n",
    "#         plt.show()\n",
    "\n",
    "    # plt.plot(signal3)\n",
    "    # plt.plot(peaks2,signal3[peaks2],'o')\n",
    "    # plt.show()\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    class PulseClustering:\n",
    "        def __init__(self, threshold):\n",
    "            self.threshold = threshold\n",
    "            self.clusters = []\n",
    "\n",
    "        def fit(self, pulses):\n",
    "            for pulse in pulses:\n",
    "                if not self.clusters:  # 如果聚类为空，创建第一个聚类\n",
    "                    self.clusters.append([pulse])\n",
    "                else:\n",
    "                    for cluster in self.clusters:\n",
    "                        center_pulse = np.mean(cluster, axis=0)  # 计算聚类中心\n",
    "                        rmse = np.sqrt(mean_squared_error(center_pulse, pulse))  # 计算RMSE\n",
    "                        if rmse < self.threshold:  # 如果RMSE低于阈值，将脉冲添加到聚类中\n",
    "                            cluster.append(pulse)\n",
    "                            break\n",
    "                    else:  # 如果脉冲与现有的所有聚类的中心的RMSE都高于阈值，创建新的聚类\n",
    "                        self.clusters.append([pulse])\n",
    "\n",
    "        def get_clusters(self):\n",
    "            return self.clusters\n",
    "\n",
    "\n",
    "    threshold = 0.000005  # 这应该是一个你选择的阈值\n",
    "\n",
    "    clustering = PulseClustering(threshold)\n",
    "    clustering.fit(stacked_array)\n",
    "\n",
    "    clusters = clustering.get_clusters()\n",
    "\n",
    "\n",
    "    num_pulses_per_cluster = [len(cluster) for cluster in clusters]\n",
    "\n",
    "    # 打印结果\n",
    "#     for i, num_pulses in enumerate(num_pulses_per_cluster):\n",
    "#         print(f\"Cluster {i+1} contains {num_pulses} pulses.\")\n",
    "\n",
    "    max_cluster = max(clusters, key=len)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 计算最大聚类的平均脉冲\n",
    "    average_pulse = np.mean(max_cluster, axis=0)\n",
    "\n",
    "#     plt.plot(average_pulse)\n",
    "    \n",
    "    p1 = peaks2[1] - avg_index[0]\n",
    "    for wz in range(10):\n",
    "        if average_pulse[p1] < average_pulse[p1+1]:\n",
    "            p1 = p1 + 1\n",
    "        elif average_pulse[p1] < average_pulse[p1-1]:\n",
    "            p1 = p1 - 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    p2 = peaks2[2] - avg_index[0]\n",
    "    for wy in range(10):\n",
    "        if average_pulse[p2] < average_pulse[p2+1]:\n",
    "            p2 = p2 + 1\n",
    "        elif average_pulse[p2] < average_pulse[p2-1]:\n",
    "            p2 = p2 - 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "#     plt.plot(p1, average_pulse[p1],'o')\n",
    "#     plt.plot(p2, average_pulse[p2],'o')\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    # 特征提取\n",
    "\n",
    "    # 平均值\n",
    "    # P1\n",
    "    # P2\n",
    "    # Skew1\n",
    "    # Skew2\n",
    "    # Kurt1\n",
    "    # Kurt2\n",
    "    # 方差\n",
    "    # PeakToPeak\n",
    "    # Zero Crossing Rate\n",
    "    # Energy \n",
    "    # 10s内有多少个周期\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.signal\n",
    "    import scipy.stats\n",
    "\n",
    "    # 假设 signal 是你的信号\n",
    "    signal = average_pulse  # 示例信号，你可以用你的信号替换\n",
    "\n",
    "    # 平均值\n",
    "    mean_val = np.mean(signal)\n",
    "\n",
    "    #  P1 P2\n",
    "    P1 = signal[p1]\n",
    "    P2 = signal[p2]\n",
    "    \n",
    "    #Sk Ku\n",
    "    Skew1 = skew(signal[:(p1+p2)//2])\n",
    "    Skew2 = skew(signal[(p1+p2)//2:])\n",
    "    Kurt1 = kurtosis(signal[:(p1+p2)//2])\n",
    "    Kurt2 = kurtosis(signal[(p1+p2)//2:])\n",
    "    \n",
    "    # 方差\n",
    "    variance = np.var(signal)\n",
    "\n",
    "    # Peak to Peak值\n",
    "    peak_to_peak = np.ptp(signal)\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    zcr = ((signal[:-1] * signal[1:]) < 0).sum()\n",
    "\n",
    "    # Energy\n",
    "    energy = np.sum(signal**2)\n",
    "    \n",
    "    # 10s内有多少个周期\n",
    "    CPS = len(peaks2)/2/10\n",
    "    \n",
    "    features = np.array([mean_val,P1,P2,Skew1,Skew2,Kurt1,Kurt2,variance,peak_to_peak,zcr,energy,CPS])\n",
    "    features_all = np.vstack([features_all, features])\n",
    "\n",
    "\n",
    "#     print(\"Mean Value:\", mean_val)\n",
    "#     print(\"Variance:\", variance)\n",
    "#     print(\"Peak to Peak:\", peak_to_peak)\n",
    "#     print(\"Zero Crossing Rate:\", zcr)\n",
    "#     print(\"Energy:\", energy)\n",
    "#     print(Skew1,Skew2,Kurt1,Kurt2,CPS,P1, P2)\n",
    "\n",
    "# feature = np.load(\"data/features_train_without_resp.npy\")\n",
    "# data = np.load(\"data/train_without_resp.npy\")\n",
    "# plt.plot(data[2,:1000])\n",
    "# plt.show()\n",
    "# print(feature[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e9ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3879, 12)\n",
      "[1.44543715e-06 3.46415075e-05 9.88661467e-06 3.37743707e+00\n",
      " 2.12629334e+00 1.11585228e+01 6.31791120e+00 2.94394620e-11\n",
      " 4.03505504e-05 1.40000000e+01 1.57643753e-09 2.30000000e+00]\n",
      "(3879, 12)\n"
     ]
    }
   ],
   "source": [
    "print(features_all.shape)\n",
    "print(features_all[0,:])\n",
    "# features_all = features_all[1:,:]\n",
    "print(features_all.shape)\n",
    "np.save(\"data/features_train_without_resp.npy\",features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1c959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "feature_train = np.load(\"data/features_train_without_resp.npy\")\n",
    "feature_test = np.load(\"data/features_test_without_resp.npy\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "feature_train_without_resp_norm = scaler.fit_transform(feature_train)\n",
    "feature_test_without_resp_norm = scaler.transform(feature_test)\n",
    "np.save(\"data/features_train_without_resp_norm.npy\", feature_train_without_resp_norm)\n",
    "np.save(\"data/features_test_without_resp_norm.npy\", feature_test_without_resp_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
